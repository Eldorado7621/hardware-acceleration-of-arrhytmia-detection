{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eldorado7621/hardware-acceleration-of-arrhytmia-detection/blob/main/cnn_cwt_an.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxnffWQLH1Fx",
        "outputId": "1c75a3e0-16a1-411c-8d9c-1ca5b81eec52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tsaug\n",
            "  Downloading tsaug-0.2.1-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.7/dist-packages (from tsaug) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tsaug) (1.21.6)\n",
            "Installing collected packages: tsaug\n",
            "Successfully installed tsaug-0.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install tsaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exBH8hjJH1Fw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.layers import Dense, Input, Dropout, Conv1D, Conv2D, MaxPool1D, GlobalMaxPool1D, MaxPool2D, GlobalMaxPool2D, Flatten, concatenate, Add, ReLU, Activation, BatchNormalization\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "\n",
        "from scipy import signal\n",
        "\n",
        "from tsaug import TimeWarp, Crop, Quantize, Drift, Reverse\n",
        "\n",
        "import pickle\n",
        "import pywt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzECqoHsIlY-",
        "outputId": "8b8d336d-05aa-415c-c30c-0bb933a001a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhYMp7dcH1Fy"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('drive/MyDrive/inputs_4class/inp_sig.pkl','rb') as f:\n",
        "    X_all = pickle.load(f)\n",
        "with open('drive/MyDrive/inputs_4class/labels.pkl','rb') as f:\n",
        "    Y_all = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-uyB05tkklQj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9iklyBaH1Fy"
      },
      "outputs": [],
      "source": [
        "Y_all = np.reshape(Y_all, ((Y_all.shape[0],1)))\n",
        "\n",
        "all_data = np.concatenate((X_all,Y_all),axis=1)\n",
        "np.random.shuffle(all_data)\n",
        "\n",
        "indx_label4 = np.where(all_data[:,600] == 4)[0]\n",
        "all_data = np.delete(all_data, indx_label4, 0)\n",
        "\n",
        "###### 80% for train, 20% for test #########\n",
        "sz = all_data.shape[0]\n",
        "\n",
        "sz_08 = int(sz * 0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YId_Vs4H1Fy"
      },
      "outputs": [],
      "source": [
        "X_train_init = all_data[:sz_08,:600]\n",
        "Y_train_init = all_data[:sz_08,600]\n",
        "\n",
        "X_test_init = all_data[sz_08:,:600]\n",
        "Y_test_init = all_data[sz_08:,600]\n",
        "\n",
        "X_train_resamp = signal.resample(X_train_init, 256, axis=1)\n",
        "X_test_resamp  = signal.resample(X_test_init, 256, axis=1)\n",
        "\n",
        "del X_test_init\n",
        "del X_train_init"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CWT FUNCTION"
      ],
      "metadata": {
        "id": "bf4nfV-HknFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cwt(data, wavelet_name, sampling_frequency=1.):\n",
        "    \n",
        "    # Currently only supported for Morlet wavelets\n",
        "    if wavelet_name == 'morl':\n",
        "        data -= np.mean(data)\n",
        "        n_orig = data.size\n",
        "        nv = 10\n",
        "        ds = 1 / nv\n",
        "        fs = sampling_frequency\n",
        "        dt = 1 / fs\n",
        "\n",
        "        # Pad data symmetrically\n",
        "        padvalue = n_orig // 2\n",
        "        x = np.concatenate((np.flipud(data[0:padvalue]), data, np.flipud(data[-padvalue:])))\n",
        "        n = x.size\n",
        "\n",
        "        # Define scales\n",
        "        _, _, wavscales = getDefaultScales(wavelet_name, n_orig, ds)\n",
        "        num_scales = wavscales.size\n",
        "\n",
        "        # Frequency vector sampling the Fourier transform of the wavelet\n",
        "        omega = np.arange(1, math.floor(n / 2) + 1, dtype=np.float64)\n",
        "        omega *= (2 * np.pi) / n\n",
        "        omega = np.concatenate((np.array([0]), omega, -omega[np.arange(math.floor((n - 1) / 2), 0, -1, dtype=int) - 1]))\n",
        "\n",
        "        # Compute FFT of the (padded) time series\n",
        "        f = np.fft.fft(x)\n",
        "\n",
        "        # Loop through all the scales and compute wavelet Fourier transform\n",
        "        psift, freq = waveft(wavelet_name, omega, wavscales)\n",
        "\n",
        "        # Inverse transform to obtain the wavelet coefficients.\n",
        "        cwtcfs = np.fft.ifft(np.kron(np.ones([num_scales, 1]), f) * psift)\n",
        "        cfs = cwtcfs[:, padvalue:padvalue + n_orig]\n",
        "        freq = freq * fs\n",
        "\n",
        "        return cfs, freq\n",
        "    else:\n",
        "        raise Exception\n",
        "\n",
        "\n",
        "def getDefaultScales(wavelet, n, ds):\n",
        "    \n",
        "    wname = wavelet\n",
        "    nv = 1 / ds\n",
        "\n",
        "    if wname == 'morl':\n",
        "\n",
        "        # Smallest useful scale (default 2 for Morlet)\n",
        "        s0 = 2\n",
        "\n",
        "        # Determine longest useful scale for wavelet\n",
        "        max_scale = n // (np.sqrt(2) * s0)\n",
        "        if max_scale <= 1:\n",
        "            max_scale = n // 2\n",
        "        max_scale = np.floor(nv * np.log2(max_scale))\n",
        "        a0 = 2 ** ds\n",
        "        scales = s0 * a0 ** np.arange(0, 31 + 1)\n",
        "    else:\n",
        "        raise Exception\n",
        "\n",
        "    return s0, ds, scales\n",
        "\n",
        "\n",
        "def waveft(wavelet, omega, scales):\n",
        "    \n",
        "    wname = wavelet\n",
        "    num_freq = omega.size\n",
        "    num_scales = scales.size\n",
        "    wft = np.zeros([num_scales, num_freq])\n",
        "\n",
        "    if wname == 'morl':\n",
        "        gC = 6\n",
        "        mul = 2\n",
        "        for jj, scale in enumerate(scales):\n",
        "            expnt = -(scale * omega - gC) ** 2 / 2 * (omega > 0)\n",
        "            wft[jj, ] = mul * np.exp(expnt) * (omega > 0)\n",
        "\n",
        "        fourier_factor = gC / (2 * np.pi)\n",
        "        frequencies = fourier_factor / scales\n",
        "\n",
        "    else:\n",
        "        raise Exception\n",
        "\n",
        "    return wft, frequencies\n",
        "\n",
        "#fs = 1000\n",
        "#t = np.linspace(0, 1, fs+1)\n",
        "#x = np.cos(2*np.pi*32*t) * np.logical_and(t >= 0.1, t < 0.3) + np.sin(2*np.pi*64*t) * (t > 0.7)\n",
        "#wgnNoise = 0.05 * np.random.standard_normal(t.shape)\n",
        "#x += wgnNoise\n",
        "#c, f = cwt(x, 'morl', sampling_frequency=fs)\n"
      ],
      "metadata": {
        "id": "ghfQVobgC-lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx0_nmTMH1Fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49c8444-fb4c-452e-ff21-3129ef62175a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "scale = range(1,33)\n",
        "fs = 1000\n",
        "train_cwt_coeffs = np.zeros((len(X_train_resamp),len(scale),256))\n",
        "#train_cwt_coeffs, freqs = pywt.cwt(X_train, scale, 'morl')\n",
        "for i in range(len(X_train_resamp)):\n",
        "    #[train_cwt_coeffs[i], freqs] = pywt.cwt(X_train_resamp[i], scale, 'morl')\n",
        "    [train_cwt_coeffs[i], freqs] = cwt(X_train_resamp[i], 'morl',fs)\n",
        "\n",
        "\n",
        "test_cwt_coeffs = np.zeros((len(X_test_resamp),len(scale),256))\n",
        "#train_cwt_coeffs, freqs = pywt.cwt(X_train, scale, 'morl')\n",
        "for i in range(len(X_test_resamp)):\n",
        "    #[test_cwt_coeffs[i], freqs] = pywt.cwt(X_test_resamp[i], scale, 'morl')\n",
        "    [test_cwt_coeffs[i], freqs] = cwt(X_test_resamp[i], 'morl',fs)\n",
        "\n",
        "del X_train_resamp\n",
        "del X_test_resamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElSXF49CH1Fz"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    nclass = 4\n",
        "    inp = tf.keras.layers.Input(shape=(32, 256, 1))\n",
        "    img_1 = Conv2D(16,3, activation=tf.keras.activations.relu, padding=\"same\")(inp)\n",
        "    img_1 = MaxPool2D(pool_size=(2,2))(img_1)\n",
        "    img_1 = Conv2D(32,3, activation=tf.keras.activations.relu, padding=\"same\")(img_1)\n",
        "    img_1 = MaxPool2D(pool_size=(2,2))(img_1)\n",
        "    img_1 = Dropout(rate=0.2)(img_1)\n",
        "    img_1 = Flatten()(img_1)\n",
        "    dense_1 = Dense(16, activation=tf.keras.activations.relu, name=\"dense_1\")(img_1)\n",
        "    dense_1 = Dense(8, activation=tf.keras.activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=tf.keras.activations.softmax, name=\"dense_3_mitbih\")(dense_1)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = tf.keras.optimizers.Adam(0.001)\n",
        "    #opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
        "    #model.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0caJO_qH1Fz",
        "outputId": "82f89096-fc10-4e0a-e260-2ea4ed9cebe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 256, 1)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 256, 16)       160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 128, 16)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 128, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 64, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8, 64, 32)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                262160    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_3_mitbih (Dense)      (None, 4)                 36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 267,132\n",
            "Trainable params: 267,132\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.3012 - acc: 0.9160\n",
            "Epoch 1: val_acc improved from -inf to 0.93941, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 208s 153ms/step - loss: 0.3012 - acc: 0.9160 - val_loss: 0.2180 - val_acc: 0.9394 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.2314 - acc: 0.9307\n",
            "Epoch 2: val_acc improved from 0.93941 to 0.94649, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 203s 150ms/step - loss: 0.2314 - acc: 0.9307 - val_loss: 0.2058 - val_acc: 0.9465 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.2137 - acc: 0.9358\n",
            "Epoch 3: val_acc improved from 0.94649 to 0.95128, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 204s 151ms/step - loss: 0.2137 - acc: 0.9358 - val_loss: 0.1788 - val_acc: 0.9513 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1956 - acc: 0.9419\n",
            "Epoch 4: val_acc did not improve from 0.95128\n",
            "1351/1351 [==============================] - 204s 151ms/step - loss: 0.1956 - acc: 0.9419 - val_loss: 0.1799 - val_acc: 0.9455 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1778 - acc: 0.9484\n",
            "Epoch 5: val_acc improved from 0.95128 to 0.95815, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 202s 149ms/step - loss: 0.1778 - acc: 0.9484 - val_loss: 0.1496 - val_acc: 0.9582 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1649 - acc: 0.9530\n",
            "Epoch 6: val_acc improved from 0.95815 to 0.96107, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 202s 150ms/step - loss: 0.1649 - acc: 0.9530 - val_loss: 0.1381 - val_acc: 0.9611 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1537 - acc: 0.9567\n",
            "Epoch 7: val_acc improved from 0.96107 to 0.96356, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 201s 149ms/step - loss: 0.1537 - acc: 0.9567 - val_loss: 0.1332 - val_acc: 0.9636 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1461 - acc: 0.9596\n",
            "Epoch 8: val_acc improved from 0.96356 to 0.96835, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 203s 150ms/step - loss: 0.1461 - acc: 0.9596 - val_loss: 0.1187 - val_acc: 0.9684 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1386 - acc: 0.9613\n",
            "Epoch 9: val_acc improved from 0.96835 to 0.97044, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 200s 148ms/step - loss: 0.1386 - acc: 0.9613 - val_loss: 0.1121 - val_acc: 0.9704 - lr: 0.0010\n",
            "Epoch 10/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1303 - acc: 0.9636\n",
            "Epoch 10: val_acc did not improve from 0.97044\n",
            "1351/1351 [==============================] - 199s 148ms/step - loss: 0.1303 - acc: 0.9636 - val_loss: 0.1143 - val_acc: 0.9692 - lr: 0.0010\n",
            "Epoch 11/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1242 - acc: 0.9650\n",
            "Epoch 11: val_acc did not improve from 0.97044\n",
            "1351/1351 [==============================] - 200s 148ms/step - loss: 0.1242 - acc: 0.9650 - val_loss: 0.1102 - val_acc: 0.9696 - lr: 0.0010\n",
            "Epoch 12/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1172 - acc: 0.9669\n",
            "Epoch 12: val_acc improved from 0.97044 to 0.97189, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 200s 148ms/step - loss: 0.1172 - acc: 0.9669 - val_loss: 0.1119 - val_acc: 0.9719 - lr: 0.0010\n",
            "Epoch 13/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1109 - acc: 0.9696\n",
            "Epoch 13: val_acc improved from 0.97189 to 0.97439, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 199s 148ms/step - loss: 0.1109 - acc: 0.9696 - val_loss: 0.1025 - val_acc: 0.9744 - lr: 0.0010\n",
            "Epoch 14/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1064 - acc: 0.9706\n",
            "Epoch 14: val_acc did not improve from 0.97439\n",
            "1351/1351 [==============================] - 202s 149ms/step - loss: 0.1064 - acc: 0.9706 - val_loss: 0.1003 - val_acc: 0.9731 - lr: 0.0010\n",
            "Epoch 15/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.1010 - acc: 0.9718\n",
            "Epoch 15: val_acc did not improve from 0.97439\n",
            "1351/1351 [==============================] - 205s 152ms/step - loss: 0.1010 - acc: 0.9718 - val_loss: 0.0990 - val_acc: 0.9744 - lr: 0.0010\n",
            "Epoch 16/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0956 - acc: 0.9733\n",
            "Epoch 16: val_acc improved from 0.97439 to 0.97460, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 203s 150ms/step - loss: 0.0956 - acc: 0.9733 - val_loss: 0.0959 - val_acc: 0.9746 - lr: 0.0010\n",
            "Epoch 17/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0902 - acc: 0.9751\n",
            "Epoch 17: val_acc improved from 0.97460 to 0.97585, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 203s 150ms/step - loss: 0.0902 - acc: 0.9751 - val_loss: 0.0935 - val_acc: 0.9758 - lr: 0.0010\n",
            "Epoch 18/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0880 - acc: 0.9747\n",
            "Epoch 18: val_acc did not improve from 0.97585\n",
            "1351/1351 [==============================] - 203s 150ms/step - loss: 0.0880 - acc: 0.9747 - val_loss: 0.0877 - val_acc: 0.9758 - lr: 0.0010\n",
            "Epoch 19/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0860 - acc: 0.9753\n",
            "Epoch 19: val_acc did not improve from 0.97585\n",
            "1351/1351 [==============================] - 203s 150ms/step - loss: 0.0860 - acc: 0.9753 - val_loss: 0.0935 - val_acc: 0.9731 - lr: 0.0010\n",
            "Epoch 20/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0826 - acc: 0.9766\n",
            "Epoch 20: val_acc did not improve from 0.97585\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1351/1351 [==============================] - 201s 149ms/step - loss: 0.0826 - acc: 0.9766 - val_loss: 0.0903 - val_acc: 0.9746 - lr: 0.0010\n",
            "Epoch 21/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0687 - acc: 0.9813\n",
            "Epoch 21: val_acc improved from 0.97585 to 0.97918, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 200s 148ms/step - loss: 0.0687 - acc: 0.9813 - val_loss: 0.0806 - val_acc: 0.9792 - lr: 1.0000e-04\n",
            "Epoch 22/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0658 - acc: 0.9819\n",
            "Epoch 22: val_acc improved from 0.97918 to 0.97939, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 202s 149ms/step - loss: 0.0658 - acc: 0.9819 - val_loss: 0.0798 - val_acc: 0.9794 - lr: 1.0000e-04\n",
            "Epoch 23/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0642 - acc: 0.9827\n",
            "Epoch 23: val_acc did not improve from 0.97939\n",
            "1351/1351 [==============================] - 201s 149ms/step - loss: 0.0642 - acc: 0.9827 - val_loss: 0.0802 - val_acc: 0.9790 - lr: 1.0000e-04\n",
            "Epoch 24/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0636 - acc: 0.9824\n",
            "Epoch 24: val_acc improved from 0.97939 to 0.97980, saving model to ECG_mitbih.h5\n",
            "1351/1351 [==============================] - 200s 148ms/step - loss: 0.0636 - acc: 0.9824 - val_loss: 0.0808 - val_acc: 0.9798 - lr: 1.0000e-04\n",
            "Epoch 25/25\n",
            "1351/1351 [==============================] - ETA: 0s - loss: 0.0624 - acc: 0.9830\n",
            "Epoch 25: val_acc did not improve from 0.97980\n",
            "1351/1351 [==============================] - 200s 148ms/step - loss: 0.0624 - acc: 0.9830 - val_loss: 0.0810 - val_acc: 0.9798 - lr: 1.0000e-04\n",
            "Test f1 score : 0.7320947297195938 \n",
            "Test accuracy score : 0.9734321645706671 \n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "file_path = \"ECG_mitbih.h5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model.fit(train_cwt_coeffs, Y_train_init, epochs=25, verbose=1, callbacks=callbacks_list, validation_split=0.1)\n",
        "#model.load_weights(file_path)\n",
        "\n",
        "pred_test = model.predict(test_cwt_coeffs)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "f1 = f1_score(Y_test_init, pred_test, average=\"macro\")\n",
        "\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test_init, pred_test)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "cm = confusion_matrix(Y_test_init, pred_test)\n",
        "cm = cm / np.sum(cm,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = 'intmodel/'\n",
        "MODEL_TFLITE = MODEL_DIR + 'avgint8model.tflite'"
      ],
      "metadata": {
        "id": "JPVdWemnSDVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('intmodel/model.h5')\n",
        "model.save('intmodel/model')"
      ],
      "metadata": {
        "id": "sBKaMCG6SE8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cwt_coeffs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hngWJneXnhUl",
        "outputId": "eb1f6c20-c960-48a4-d8f9-15adb265f213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xJf7_fyuBXc",
        "outputId": "6ad1c58b-af87-4248-f0ac-c5d668ffa752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 256, 1)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 256, 16)       160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 128, 16)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 128, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 64, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8, 64, 32)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                262160    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_3_mitbih (Dense)      (None, 4)                 36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 267,132\n",
            "Trainable params: 267,132\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_cwt_coeffs[0].dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_m2BmO_uKQB",
        "outputId": "10dd403d-6154-40e1-fd10-5b6ef316297a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('intmodel/model')\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Enforce integer only quantization\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "# Provide a representative dataset to ensure we quantize correctly.\n",
        "def representative_dataset():\n",
        "    for i in range(500):\n",
        "        yield([np.float32(train_cwt_coeffs[i]).reshape(1, 32,256,1)])\n",
        "\n",
        "\n",
        "converter.representative_dataset = representative_dataset\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXP8D-k2SMA6",
        "outputId": "98acdf18-8f3d-4c79-d611-d2c534009cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "272432"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4C7nMnfsSNZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}